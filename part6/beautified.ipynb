{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 6: Beautified — Modular Name Generation\n",
        "\n",
        "This notebook uses:\n",
        "- **`data_loading`** — dataset download, normalization, vocabularies, and validation\n",
        "- **`model`** — `CategoryConditionedNameModel` (torch.nn.Module) for category-conditioned next-character prediction\n",
        "\n",
        "No inline layer lists; everything is organized in modules for readability and reuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6d6933",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure project root is on path (run from repo root or from part6)\n",
        "root = Path.cwd() if Path.cwd().name != \"part6\" else Path.cwd().parent\n",
        "if str(root) not in sys.path:\n",
        "    sys.path.insert(0, str(root))\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from part6.data_loading import (\n",
        "    load_words_and_categories,\n",
        "    build_character_vocabulary,\n",
        "    build_category_vocabulary,\n",
        "    get_train_val_test_splits,\n",
        "    validate_dataset,\n",
        ")\n",
        "from part6.model import CategoryConditionedNameModel, ModelConfig\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"isaacbenge/fantasy-for-markov-generator\")\n",
        "print(f\"Dataset path: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load words and categories (optional: add extra CSV)\n",
        "extra_csv = Path(\"data/forgotten_realms_inhabitants_by_race.csv\")\n",
        "if not extra_csv.is_file():\n",
        "    extra_csv = Path(\"../data/forgotten_realms_inhabitants_by_race.csv\")\n",
        "extra_csv = str(extra_csv) if extra_csv.is_file() else None\n",
        "\n",
        "words, categories = load_words_and_categories(\n",
        "    path,\n",
        "    extra_csv_path=extra_csv,\n",
        "    extra_name_column=\"name\",\n",
        "    extra_category_column=\"source_category\",\n",
        ")\n",
        "print(f\"Loaded {len(words)} words with {len(categories)} categories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build vocabularies\n",
        "char_vocab = build_character_vocabulary(words)\n",
        "cat_vocab = build_category_vocabulary(categories)\n",
        "\n",
        "print(f\"Character vocab size: {char_vocab.size}\")\n",
        "print(f\"Category vocab size: {cat_vocab.size}\")\n",
        "print(f\"Sample chars: {char_vocab.itos}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/val/test splits and dataset building\n",
        "block_size = 24\n",
        "\n",
        "(Xtr, Ytr, Ctr), (Xdev, Ydev, Cdev), (Xte, Yte, Cte) = get_train_val_test_splits(\n",
        "    words,\n",
        "    cat_vocab.normalized_categories,\n",
        "    char_vocab,\n",
        "    cat_vocab,\n",
        "    block_size,\n",
        "    train_frac=0.95,\n",
        "    val_frac=0.03,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(f\"Train: {Xtr.shape[0]}, Val: {Xdev.shape[0]}, Test: {Xte.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate datasets\n",
        "validate_dataset(Xtr, Ytr, Ctr, char_vocab, cat_vocab)\n",
        "\n",
        "# Sanity checks before training\n",
        "assert Ytr.max() < char_vocab.size and Ytr.min() >= 0\n",
        "assert not torch.isnan(Ytr).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788459eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model and optimizer\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "config = ModelConfig(\n",
        "    vocab_size=char_vocab.size,\n",
        "    cat_vocab_size=cat_vocab.size,\n",
        "    block_size=block_size,\n",
        "    n_embd=64,\n",
        "    n_hidden=512,\n",
        "    num_heads=8,\n",
        "    num_attention_blocks=5,\n",
        "    num_mlp_layers=1,\n",
        "    cat_emb_dim=32,\n",
        "    dropout=0.1,\n",
        "    last_layer_scale=0.1,\n",
        ")\n",
        "model = CategoryConditionedNameModel(config).to(device)\n",
        "\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Parameters: {n_params:,}\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "max_steps = 300_000\n",
        "batch_size = 256\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "    Xb = Xtr[ix].to(device)\n",
        "    Yb = Ytr[ix].to(device)\n",
        "    Cb = Ctr[ix].to(device)\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits, loss = model(Xb, Cb, targets=Yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    lossi.append(loss.log10().item())\n",
        "    if (i + 1) % 10_000 == 0:\n",
        "        mem = torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0\n",
        "        print(f\"{i+1:7d}/{max_steps:7d}: loss={loss.item():.4f}  GPU={mem:.2f}GB\")\n",
        "\n",
        "print(\"Training done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))\n",
        "plt.xlabel(\"Step (1k)\")\n",
        "plt.ylabel(\"log10(loss)\")\n",
        "plt.title(\"Training loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation: train and val loss\n",
        "@torch.no_grad()\n",
        "def split_loss(split: str) -> float:\n",
        "    model.eval()\n",
        "    splits = {\n",
        "        \"train\": (Xtr, Ytr, Ctr),\n",
        "        \"val\": (Xdev, Ydev, Cdev),\n",
        "        \"test\": (Xte, Yte, Cte),\n",
        "    }\n",
        "    X, Y, C = splits[split]\n",
        "    n = min(2048, X.shape[0])\n",
        "    Xb = X[:n].to(device)\n",
        "    Yb = Y[:n].to(device)\n",
        "    Cb = C[:n].to(device)\n",
        "    logits, _ = model(Xb, Cb, targets=Yb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "    return loss.item()\n",
        "\n",
        "# print(f\"Train loss: {split_loss('train'):.4f}\")\n",
        "print(f\"Val loss:   {split_loss('val'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate names for a given category\n",
        "gen = torch.Generator(device=device).manual_seed(2147483647 + 1)\n",
        "\n",
        "cat_name = \"dwarves\"\n",
        "cat_idx = next((k for k, v in cat_vocab.itos.items() if v.lower() == cat_name), 0)\n",
        "\n",
        "for _ in range(15):\n",
        "    name = model.generate(cat_idx, char_vocab.itos, generator=gen)\n",
        "    print(f\"[{cat_name}] {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random category sampling\n",
        "import random\n",
        "\n",
        "gen = torch.Generator(device=device).manual_seed(2147483647 + 2)\n",
        "cat_indices = list(cat_vocab.itos.keys())\n",
        "\n",
        "for _ in range(10):\n",
        "    c = random.choice(cat_indices)\n",
        "    cat_label = cat_vocab.itos[c]\n",
        "    name = model.generate(c, char_vocab.itos, generator=gen)\n",
        "    print(f\"[{cat_label}] {name}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
