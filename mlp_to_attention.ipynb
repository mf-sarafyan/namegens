{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79288c9c",
   "metadata": {},
   "source": [
    "# MLP Exercise - fantasy name generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6b4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5060\n",
      "Memory: 7.96 GB\n",
      "Cleared CUDA cache\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "from src.layers import Linear, BatchNorm1d, LayerNorm1d, Tanh, Dropout\n",
    "%matplotlib inline\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    # Clear any existing CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Cleared CUDA cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfcb2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\namegens\\namegens\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Fern_PC II\\.cache\\kagglehub\\datasets\\isaacbenge\\fantasy-for-markov-generator\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"isaacbenge/fantasy-for-markov-generator\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca3d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data, normalize strings \n",
    "import glob\n",
    "import pandas as pd \n",
    "allcsvs = []\n",
    "for f in glob.glob(path+\"/*.csv\") + [\"./names_clean.csv\", \"./forgotten_realms_inhabitants_by_race.csv\"]:\n",
    "# for f in [\"./forgotten_realms_inhabitants_by_race.csv\"]:\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    series = (df[0].str.normalize('NFKD')\n",
    "                   .str.encode('ascii', errors='ignore')\n",
    "                   .str.decode('utf-8')\n",
    "                   .str.lower()\n",
    "                   .str.replace(r'[^\\w\\s]', '')\n",
    "                   .str.replace(r'\\d+', '', regex=True)\n",
    "                   .str.replace('/', '')\n",
    "                   .str.replace('(', '')\n",
    "                   .str.replace(')', '')\n",
    "                   .str.replace('\"', \"'\")\n",
    "                   .str.replace('_', ' ')\n",
    "                   .str.replace('`', \"'\")\n",
    "                   .str.replace('.', \"\")\n",
    "                   .str.strip()\n",
    "                   \n",
    "                   )\n",
    "\n",
    "    allcsvs.append(series)\n",
    "\n",
    "# Adding names from names_clean.csv\n",
    "words = pd.concat(allcsvs).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7627eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46748\n",
      "\n",
      "============================================================\n",
      "CHARACTER ANALYSIS\n",
      "============================================================\n",
      "{1: ' ', 2: \"'\", 3: ',', 4: '-', 5: 'a', 6: 'b', 7: 'c', 8: 'd', 9: 'e', 10: 'f', 11: 'g', 12: 'h', 13: 'i', 14: 'j', 15: 'k', 16: 'l', 17: 'm', 18: 'n', 19: 'o', 20: 'p', 21: 'q', 22: 'r', 23: 's', 24: 't', 25: 'u', 26: 'v', 27: 'w', 28: 'x', 29: 'y', 30: 'z', 0: '.'}\n",
      "31\n",
      "Total unique characters in processed words: 30\n",
      "Characters in vocabulary (stoi): 31\n",
      "\n",
      "Characters in words but NOT in vocabulary:\n",
      "  ✓ All characters are in vocabulary\n",
      "\n",
      "Characters in vocabulary but NOT in words:\n",
      "  '.' (ord=46, repr='.')\n",
      "\n",
      "Empty strings found: 0\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "words[:8]\n",
    "\n",
    "# Debug: Check what characters are actually in the processed words\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CHARACTER ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "all_chars_in_words = set()\n",
    "for w in words:\n",
    "  all_chars_in_words.update(w)\n",
    "\n",
    "  # build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)\n",
    "\n",
    "print(f\"Total unique characters in processed words: {len(all_chars_in_words)}\")\n",
    "print(f\"Characters in vocabulary (stoi): {len(stoi)}\")\n",
    "print(f\"\\nCharacters in words but NOT in vocabulary:\")\n",
    "missing_from_vocab = all_chars_in_words - set(stoi.keys())\n",
    "if missing_from_vocab:\n",
    "  for ch in sorted(missing_from_vocab):\n",
    "    print(f\"  '{ch}' (ord={ord(ch)}, repr={repr(ch)})\")\n",
    "else:\n",
    "  print(\"  ✓ All characters are in vocabulary\")\n",
    "\n",
    "print(f\"\\nCharacters in vocabulary but NOT in words:\")\n",
    "extra_in_vocab = set(stoi.keys()) - all_chars_in_words\n",
    "if extra_in_vocab:\n",
    "  for ch in sorted(extra_in_vocab):\n",
    "    print(f\"  '{ch}' (ord={ord(ch)}, repr={repr(ch)})\")\n",
    "else:\n",
    "  print(\"  ✓ All vocabulary characters appear in words\")\n",
    "\n",
    "# Check for empty strings\n",
    "empty_count = sum(1 for w in words if not w or len(w.strip()) == 0)\n",
    "print(f\"\\nEmpty strings found: {empty_count}\")\n",
    "if empty_count > 0:\n",
    "  print(\"  ⚠️  WARNING: Empty strings will cause issues!\")\n",
    "  empty_examples = [w for w in words[:100] if not w or len(w.strip()) == 0]\n",
    "  print(f\"  First few empty examples: {empty_examples[:10]}\")\n",
    "\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6924e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All words processed successfully\n",
      "torch.Size([360557, 16]) torch.Size([360557])\n",
      "✓ All words processed successfully\n",
      "torch.Size([45603, 16]) torch.Size([45603])\n",
      "✓ All words processed successfully\n",
      "torch.Size([45572, 16]) torch.Size([45572])\n",
      "Dataset kept on CPU (saves GPU memory)\n",
      "  Training samples: 360557\n",
      "  Validation samples: 45603\n",
      "  Test samples: 45572\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 16 # context length: how many characters do we take to predict the next one?\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  # Debug: Track problematic words\n",
    "  missing_chars = set()\n",
    "  empty_words = []\n",
    "  problematic_words = []\n",
    "  \n",
    "  for idx, w in enumerate(words):\n",
    "    # Check for empty strings\n",
    "    if not w or len(w.strip()) == 0:\n",
    "      empty_words.append((idx, w))\n",
    "      continue\n",
    "    \n",
    "    context = [0] * block_size\n",
    "    word_chars = []\n",
    "    \n",
    "    try:\n",
    "      for ch in w + '.':\n",
    "        if ch not in stoi:\n",
    "          missing_chars.add(ch)\n",
    "          problematic_words.append((idx, w, f\"Missing char: '{ch}' (ord={ord(ch)})\"))\n",
    "          raise KeyError(f\"Character '{ch}' not in stoi\")\n",
    "        ix = stoi[ch]\n",
    "        word_chars.append((ch, ix))\n",
    "        X.append(context.copy())\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "    except KeyError as e:\n",
    "      # Skip this word but continue processing\n",
    "      if len(problematic_words) <= 10:  # Only print first 10\n",
    "        print(f\"  ERROR at word {idx}: '{w}' - {e}\")\n",
    "      continue\n",
    "  \n",
    "  # Print debugging info\n",
    "  if missing_chars:\n",
    "    print(f\"\\n⚠️  Found {len(missing_chars)} missing characters:\")\n",
    "    for ch in sorted(missing_chars):\n",
    "      print(f\"    '{ch}' (ord={ord(ch)}, repr={repr(ch)})\")\n",
    "  \n",
    "  if empty_words:\n",
    "    print(f\"\\n⚠️  Found {len(empty_words)} empty words (first 10):\")\n",
    "    for idx, w in empty_words[:10]:\n",
    "      print(f\"    Index {idx}: {repr(w)}\")\n",
    "  \n",
    "  if problematic_words:\n",
    "    print(f\"\\n⚠️  Found {len(problematic_words)} problematic words (first 10):\")\n",
    "    for idx, w, reason in problematic_words[:10]:\n",
    "      print(f\"    Index {idx}: '{w}' - {reason}\")\n",
    "  \n",
    "  if not missing_chars and not empty_words and not problematic_words:\n",
    "    print(\"✓ All words processed successfully\")\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n",
    "\n",
    "# Keep dataset on CPU - only move batches to GPU during training (saves GPU memory)\n",
    "print(f\"Dataset kept on CPU (saves GPU memory)\")\n",
    "print(f\"  Training samples: {len(Xtr)}\")\n",
    "print(f\"  Validation samples: {len(Xdev)}\")\n",
    "print(f\"  Test samples: {len(Xte)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167a5854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2379550\n",
      "Moved 2379550 parameters to cuda\n",
      "GPU Memory - Allocated: 0.01 GB, Reserved: 0.03 GB, Total: 8.55 GB\n",
      "Available: 8.52 GB\n"
     ]
    }
   ],
   "source": [
    "n_embd = 32 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 256 # the number of neurons in the hidden layer of the MLP\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "\n",
    "# Self-Attention layer class (single head)\n",
    "class SelfAttention:\n",
    "  def __init__(self, n_embd, head_size, block_size, dropout=0.0):\n",
    "    self.n_embd = n_embd\n",
    "    self.head_size = head_size\n",
    "    self.block_size = block_size\n",
    "    # Create Q, K, V projection matrices\n",
    "    self.key = Linear(n_embd, head_size, bias=False)\n",
    "    self.query = Linear(n_embd, head_size, bias=False)\n",
    "    self.value = Linear(n_embd, head_size, bias=False)\n",
    "    # Output projection\n",
    "    self.proj = Linear(head_size, n_embd, bias=False)\n",
    "    # Layer normalization after attention to stabilize gradients\n",
    "    self.ln = LayerNorm1d(n_embd)\n",
    "    # Causal mask: lower triangular matrix to prevent looking at future tokens\n",
    "    self.register_buffer = lambda name, val: setattr(self, name, val)\n",
    "    tril = torch.tril(torch.ones(block_size, block_size, device=device))\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    self.register_buffer('mask', tril)\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    # x shape: (batch_size, block_size, n_embd)\n",
    "    B, T, C = x.shape\n",
    "    \n",
    "    # Compute Q, K, V\n",
    "    k = self.key(x)   # (B, T, head_size)\n",
    "    q = self.query(x) # (B, T, head_size)\n",
    "    v = self.value(x) # (B, T, head_size)\n",
    "    \n",
    "    # Compute attention scores: (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
    "    wei = q @ k.transpose(-2, -1) * self.head_size**-0.5  # scaled dot-product\n",
    "    wei = wei.masked_fill(self.mask[:T, :T] == 0, float('-inf'))  # apply causal mask\n",
    "    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
    "    \n",
    "    # Apply attention to values\n",
    "    out = wei @ v  # (B, T, head_size)\n",
    "    \n",
    "    # Output projection\n",
    "    out = self.proj(out)  # (B, T, n_embd)\n",
    "    \n",
    "    # Layer normalization to stabilize gradients and prevent NaN\n",
    "    out = self.ln(out)  # (B, T, n_embd)\n",
    "    out = self.dropout(out)\n",
    "    self.out = out\n",
    "    return out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return (self.key.parameters() + self.query.parameters() + \n",
    "            self.value.parameters() + self.proj.parameters() + \n",
    "            self.ln.parameters())\n",
    "\n",
    "# Multi-Head Self-Attention layer class\n",
    "class MultiHeadAttention:\n",
    "  def __init__(self, n_embd, num_heads, head_size, block_size, dropout=0.0):\n",
    "    self.n_embd = n_embd\n",
    "    self.num_heads = num_heads\n",
    "    self.head_size = head_size\n",
    "    self.block_size = block_size\n",
    "    # Create Q, K, V projection matrices for all heads at once\n",
    "    # Project to num_heads * head_size, then we'll split into heads\n",
    "    self.key = Linear(n_embd, num_heads * head_size, bias=False)\n",
    "    self.query = Linear(n_embd, num_heads * head_size, bias=False)\n",
    "    self.value = Linear(n_embd, num_heads * head_size, bias=False)\n",
    "    # Output projection (concatenated heads -> n_embd)\n",
    "    self.proj = Linear(num_heads * head_size, n_embd, bias=False)\n",
    "    # Layer normalization after attention to stabilize gradients\n",
    "    self.ln = LayerNorm1d(n_embd)\n",
    "    # Causal mask: lower triangular matrix to prevent looking at future tokens\n",
    "    self.register_buffer = lambda name, val: setattr(self, name, val)\n",
    "    tril = torch.tril(torch.ones(block_size, block_size)).to(device)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.register_buffer('mask', tril)\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    # x shape: (batch_size, block_size, n_embd)\n",
    "    B, T, C = x.shape\n",
    "    \n",
    "    # Compute Q, K, V for all heads\n",
    "    k = self.key(x)   # (B, T, num_heads * head_size)\n",
    "    q = self.query(x) # (B, T, num_heads * head_size)\n",
    "    v = self.value(x) # (B, T, num_heads * head_size)\n",
    "    \n",
    "    # Reshape to separate heads: (B, T, num_heads, head_size)\n",
    "    # Then transpose to: (B, num_heads, T, head_size)\n",
    "    k = k.view(B, T, self.num_heads, self.head_size).transpose(1, 2)  # (B, num_heads, T, head_size)\n",
    "    q = q.view(B, T, self.num_heads, self.head_size).transpose(1, 2)  # (B, num_heads, T, head_size)\n",
    "    v = v.view(B, T, self.num_heads, self.head_size).transpose(1, 2)  # (B, num_heads, T, head_size)\n",
    "    \n",
    "    # Compute attention scores for all heads in parallel\n",
    "    # (B, num_heads, T, head_size) @ (B, num_heads, head_size, T) -> (B, num_heads, T, T)\n",
    "    wei = q @ k.transpose(-2, -1) * self.head_size**-0.5  # scaled dot-product\n",
    "    wei = wei.masked_fill(self.mask[:T, :T] == 0, float('-inf'))  # apply causal mask\n",
    "    wei = F.softmax(wei, dim=-1)  # (B, num_heads, T, T)\n",
    "    \n",
    "    # Apply attention to values\n",
    "    out = wei @ v  # (B, num_heads, T, head_size)\n",
    "    \n",
    "    # Concatenate heads: (B, num_heads, T, head_size) -> (B, T, num_heads * head_size)\n",
    "    out = out.transpose(1, 2).contiguous().view(B, T, self.num_heads * self.head_size)\n",
    "    \n",
    "    # Output projection\n",
    "    out = self.proj(out)  # (B, T, n_embd)\n",
    "    \n",
    "    # Layer normalization to stabilize gradients and prevent NaN\n",
    "    out = self.ln(out)  # (B, T, n_embd)\n",
    "    out = self.dropout(out)\n",
    "    self.out = out\n",
    "    return out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return (self.key.parameters() + self.query.parameters() + \n",
    "            self.value.parameters() + self.proj.parameters() + \n",
    "            self.ln.parameters())\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Create linear layer to transform embeddings before attention\n",
    "# This will transform from n_embd to n_hidden dimension\n",
    "linear_pre_attention = Linear(n_embd, n_hidden, bias=False)\n",
    "\n",
    "# Multi-head attention configuration\n",
    "num_heads = 4  # Number of attention heads\n",
    "head_size = n_hidden // num_heads  # Each head processes head_size dimensions\n",
    "# Ensure head_size * num_heads equals n_hidden\n",
    "assert n_hidden % num_heads == 0, f\"n_hidden ({n_hidden}) must be divisible by num_heads ({num_heads})\"\n",
    "\n",
    "# Choose attention type:\n",
    "# Option 1: Single-head attention (original)\n",
    "# attention = SelfAttention(n_hidden, n_hidden, block_size, 0.1)\n",
    "\n",
    "# Option 2: Multi-head attention (recommended for better representation)\n",
    "attention1 = MultiHeadAttention(n_hidden, num_heads, head_size, block_size, 0.1)\n",
    "attention2 = MultiHeadAttention(n_hidden, num_heads, head_size, block_size, 0.1)\n",
    "attention3 = MultiHeadAttention(n_hidden, num_heads, head_size, block_size, 0.1)\n",
    "attention4 = MultiHeadAttention(n_hidden, num_heads, head_size, block_size, 0.1)\n",
    "attention5 = MultiHeadAttention(n_hidden, num_heads, head_size, block_size, 0.1)\n",
    "\n",
    "# Wrapper class to apply linear layer to 3D input (position-wise)\n",
    "# Applies linear transformation to each position independently\n",
    "class Linear3D:\n",
    "  def __init__(self, linear_layer):\n",
    "    self.linear = linear_layer\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    # x is 3D: (batch, seq_len, in_dim)\n",
    "    B, T, C = x.shape\n",
    "    # Reshape to 2D: (batch * seq_len, in_dim)\n",
    "    x = x.view(B * T, C)\n",
    "    # Apply linear layer\n",
    "    x = self.linear(x)  # (batch * seq_len, out_dim)\n",
    "    # Reshape back to 3D: (batch, seq_len, out_dim)\n",
    "    x = x.view(B, T, -1)\n",
    "    self.out = x\n",
    "    return x\n",
    "  \n",
    "  def parameters(self):\n",
    "    return self.linear.parameters()\n",
    "\n",
    "# Wrapper class for attention that keeps 3D shape (for stacking multiple attention layers)\n",
    "class Attention3D:\n",
    "  def __init__(self, attention_layer):\n",
    "    self.attention = attention_layer\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    # x is 3D: (batch, seq_len, embd)\n",
    "    x = self.attention(x)  # (batch, seq_len, embd) - stays 3D\n",
    "    self.out = x\n",
    "    return x\n",
    "  \n",
    "  def parameters(self):\n",
    "    return self.attention.parameters()\n",
    "\n",
    "# Wrapper class to integrate attention into layers list\n",
    "# Handles 3D -> 2D conversion (attention outputs 3D, MLP expects 2D)\n",
    "class AttentionFlatten:\n",
    "  def __init__(self, attention_layer):\n",
    "    self.attention = attention_layer\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    # x is 3D: (batch, seq_len, embd)\n",
    "    x = self.attention(x)  # (batch, seq_len, embd)\n",
    "    # Flatten to 2D: (batch, seq_len * embd)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    self.out = x \n",
    "    return x\n",
    "  \n",
    "  def parameters(self):\n",
    "    return self.attention.parameters()\n",
    "\n",
    "layers = [\n",
    "  Linear3D(linear_pre_attention),  # Transform embeddings: (batch, seq_len, n_embd) -> (batch, seq_len, n_hidden)\n",
    "  Attention3D(attention1),  # First attention layer: (batch, seq_len, n_hidden) -> (batch, seq_len, n_hidden)\n",
    "  Attention3D(attention2),  # Second attention layer: (batch, seq_len, n_hidden) -> (batch, seq_len, n_hidden)\n",
    "  Attention3D(attention3),  # Second attention layer: (batch, seq_len, n_hidden) -> (batch, seq_len, n_hidden)\n",
    "  Attention3D(attention4),  # Second attention layer: (batch, seq_len, n_hidden) -> (batch, seq_len, n_hidden)\n",
    "  AttentionFlatten(attention5),  # Third attention + LayerNorm + Flatten: (batch, seq_len, n_hidden) -> (batch, seq_len * n_hidden)\n",
    "  Linear(n_hidden * block_size, n_hidden, bias=False), LayerNorm1d(n_hidden), Dropout(0.1), Tanh(),\n",
    "  Linear(           n_hidden, vocab_size, bias=False), LayerNorm1d(vocab_size),\n",
    "]\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  layers[-1].gamma *= 0.1\n",
    "  #layers[-1].weight *= 0.1\n",
    "  # all other layers: apply gain\n",
    "  for layer in layers[:-1]:\n",
    "    if isinstance(layer, Linear):\n",
    "      layer.weight *= 1.0 #5/3\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# Move all parameters to GPU\n",
    "C = C.to(device)\n",
    "for p in parameters:\n",
    "  p.data = p.data.to(device)\n",
    "\n",
    "# Move all attention masks to GPU\n",
    "for layer in layers:\n",
    "  if hasattr(layer, 'attention') and hasattr(layer.attention, 'mask'):\n",
    "    layer.attention.mask = layer.attention.mask.to(device)\n",
    "\n",
    "print(f\"Moved {sum(p.nelement() for p in parameters)} parameters to {device}\")\n",
    "\n",
    "# Check GPU memory usage after moving parameters\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB, Total: {total:.2f} GB\")\n",
    "    print(f\"Available: {total - reserved:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edeb9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training - Allocated: 0.01 GB, Reserved: 0.03 GB\n",
      "\n",
      "============================================================\n",
      "DATASET VALIDATION & DEBUGGING\n",
      "============================================================\n",
      "Vocab size: 31\n",
      "Vocab chars: [' ', \"'\", ',', '-', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "Dataset shapes:\n",
      "  Xtr: torch.Size([360557, 16]), Ytr: torch.Size([360557])\n",
      "  Xdev: torch.Size([45603, 16]), Ydev: torch.Size([45603])\n",
      "  Xte: torch.Size([45572, 16]), Yte: torch.Size([45572])\n",
      "\n",
      "Checking for NaN values:\n",
      "  Xtr has NaN: False\n",
      "  Ytr has NaN: False\n",
      "\n",
      "Checking index ranges:\n",
      "  Xtr min/max: 0/30 (valid: 0-30)\n",
      "  Ytr min/max: 0/30 (valid: 0-30)\n",
      "\n",
      "Sample data verification (first 5 training samples):\n",
      "  [0] X: ................ -> Y: c (idx=7)\n",
      "  [1] X: ...............c -> Y: h (idx=12)\n",
      "  [2] X: ..............ch -> Y: e (idx=9)\n",
      "  [3] X: .............che -> Y: n (idx=18)\n",
      "  [4] X: ............chen -> Y: . (idx=0)\n",
      "\n",
      "============================================================\n",
      "✓ All data validation checks passed!\n",
      "============================================================\n",
      "\n",
      "      0/ 200000: 3.4450 | GPU Mem: 0.12GB/0.20GB\n",
      "  10000/ 200000: 2.5180 | GPU Mem: 0.12GB/0.21GB\n",
      "  20000/ 200000: 2.1891 | GPU Mem: 0.12GB/0.21GB\n",
      "  30000/ 200000: 2.4951 | GPU Mem: 0.12GB/0.21GB\n",
      "  40000/ 200000: 2.2158 | GPU Mem: 0.12GB/0.21GB\n",
      "  50000/ 200000: 2.2591 | GPU Mem: 0.12GB/0.21GB\n",
      "  60000/ 200000: 2.2037 | GPU Mem: 0.12GB/0.21GB\n",
      "  70000/ 200000: 2.2640 | GPU Mem: 0.12GB/0.21GB\n",
      "  80000/ 200000: 2.2118 | GPU Mem: 0.12GB/0.21GB\n",
      "  90000/ 200000: 2.1402 | GPU Mem: 0.12GB/0.21GB\n",
      " 100000/ 200000: 2.0519 | GPU Mem: 0.12GB/0.21GB\n",
      " 110000/ 200000: 2.0063 | GPU Mem: 0.12GB/0.21GB\n",
      " 120000/ 200000: 2.0734 | GPU Mem: 0.12GB/0.21GB\n",
      " 130000/ 200000: 2.0789 | GPU Mem: 0.12GB/0.21GB\n",
      " 140000/ 200000: 2.2935 | GPU Mem: 0.12GB/0.21GB\n",
      " 150000/ 200000: 2.1339 | GPU Mem: 0.12GB/0.21GB\n",
      " 160000/ 200000: 2.1570 | GPU Mem: 0.12GB/0.21GB\n",
      " 170000/ 200000: 1.9452 | GPU Mem: 0.12GB/0.21GB\n",
      " 180000/ 200000: 2.1000 | GPU Mem: 0.12GB/0.21GB\n",
      " 190000/ 200000: 2.2032 | GPU Mem: 0.12GB/0.21GB\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 128  \n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "# Clear any previous GPU errors and check memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    # Reset CUDA error state if any\n",
    "    try:\n",
    "        torch.cuda.synchronize()\n",
    "    except:\n",
    "        print(\"Warning: GPU had previous error state - consider restarting kernel\")\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    print(f\"Before training - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "\n",
    "# Comprehensive data validation and debugging\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATASET VALIDATION & DEBUGGING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Vocab chars: {sorted(stoi.keys())}\")\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"  Xtr: {Xtr.shape}, Ytr: {Ytr.shape}\")\n",
    "print(f\"  Xdev: {Xdev.shape}, Ydev: {Ydev.shape}\")\n",
    "print(f\"  Xte: {Xte.shape}, Yte: {Yte.shape}\")\n",
    "\n",
    "# Check for NaN values\n",
    "print(f\"\\nChecking for NaN values:\")\n",
    "x_nan = torch.isnan(Xtr).any().item()\n",
    "y_nan = torch.isnan(Ytr).any().item()\n",
    "print(f\"  Xtr has NaN: {x_nan}\")\n",
    "print(f\"  Ytr has NaN: {y_nan}\")\n",
    "if x_nan or y_nan:\n",
    "  print(\"  ⚠️  WARNING: NaN values found!\")\n",
    "\n",
    "# Check for invalid indices\n",
    "print(f\"\\nChecking index ranges:\")\n",
    "x_min, x_max = Xtr.min().item(), Xtr.max().item()\n",
    "y_min, y_max = Ytr.min().item(), Ytr.max().item()\n",
    "print(f\"  Xtr min/max: {x_min}/{x_max} (valid: 0-{vocab_size-1})\")\n",
    "print(f\"  Ytr min/max: {y_min}/{y_max} (valid: 0-{vocab_size-1})\")\n",
    "\n",
    "if x_max >= vocab_size:\n",
    "  print(f\"  ⚠️  ERROR: Xtr has invalid indices >= vocab_size!\")\n",
    "  invalid_x = (Xtr >= vocab_size).nonzero(as_tuple=True)\n",
    "  print(f\"  Found {len(invalid_x[0])} invalid X indices\")\n",
    "  if len(invalid_x[0]) > 0:\n",
    "    print(f\"  First 10 invalid positions: {invalid_x[0][:10].tolist()}\")\n",
    "\n",
    "if y_max >= vocab_size:\n",
    "  print(f\"  ⚠️  ERROR: Ytr has invalid indices >= vocab_size!\")\n",
    "  invalid_y = (Ytr >= vocab_size).nonzero(as_tuple=True)\n",
    "  print(f\"  Found {len(invalid_y[0])} invalid Y indices\")\n",
    "  if len(invalid_y[0]) > 0:\n",
    "    print(f\"  First 10 invalid positions: {invalid_y[0][:10].tolist()}\")\n",
    "\n",
    "# Check for negative indices\n",
    "if x_min < 0:\n",
    "  print(f\"  ⚠️  WARNING: Xtr has negative indices!\")\n",
    "if y_min < 0:\n",
    "  print(f\"  ⚠️  WARNING: Ytr has negative indices!\")\n",
    "\n",
    "# Sample some data to verify encoding\n",
    "print(f\"\\nSample data verification (first 5 training samples):\")\n",
    "for i in range(min(5, len(Xtr))):\n",
    "  x_seq = Xtr[i].tolist()\n",
    "  y_val = Ytr[i].item()\n",
    "  x_str = ''.join(['.' if tok == 0 else (itos[tok] if tok in itos else f'<{tok}>') for tok in x_seq])\n",
    "  y_str = '.' if y_val == 0 else (itos[y_val] if y_val in itos else f'<{y_val}>')\n",
    "  print(f\"  [{i}] X: {x_str} -> Y: {y_str} (idx={y_val})\")\n",
    "\n",
    "# Final assertions\n",
    "print(f\"\\n{'='*60}\")\n",
    "assert Xtr.max() < vocab_size, f\"Xtr has invalid indices >= vocab_size ({vocab_size})\"\n",
    "assert Ytr.max() < vocab_size, f\"Ytr has invalid indices >= vocab_size ({vocab_size})\"\n",
    "assert Xtr.min() >= 0, f\"Xtr has negative indices\"\n",
    "assert Ytr.min() >= 0, f\"Ytr has negative indices\"\n",
    "assert not torch.isnan(Xtr).any(), \"Xtr contains NaN values\"\n",
    "assert not torch.isnan(Ytr).any(), \"Ytr contains NaN values\"\n",
    "print(\"✓ All data validation checks passed!\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  # Move only the batch to GPU (dataset stays on CPU)\n",
    "  Xb, Yb = Xtr[ix].to(device), Ytr[ix].to(device) # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors: (batch_size, block_size, n_embd)\n",
    "  \n",
    "  # Pass through all layers (attention + normalization are now in the layers list)\n",
    "  x = emb\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  layers[1].attention.out.retain_grad()  # Store attention output gradient\n",
    "  for layer in layers:\n",
    "    layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # Ensure all gradients are on GPU (in case any were computed on CPU)\n",
    "  for p in parameters:\n",
    "    if p.grad is not None:\n",
    "      p.grad = p.grad.to(device)\n",
    "  \n",
    "  # update\n",
    "  lr = 0.2 if i < 150000 else 0.02 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    if torch.cuda.is_available():\n",
    "      allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "      reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f} | GPU Mem: {allocated:.2f}GB/{reserved:.2f}GB')\n",
    "    else:\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  with torch.no_grad():\n",
    "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])\n",
    "\n",
    "  #if i >= 1000:\n",
    "  #  break # AFTER_DEBUG: would take out obviously to run full optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a8d9e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2e9d0162ad0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plt.plot(lossi)\n",
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  if p.ndim == 2:\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append('param %d' % i)\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a2b168",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacity of 7.96 GiB of which 5.87 GiB is free. Of the allocated memory 816.71 MiB is allocated by PyTorch, and 63.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[32m     21\u001b[39m   layer.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43msplit_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m split_loss(\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\namegens\\namegens\\.env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36msplit_loss\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m     13\u001b[39m x = emb\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m   x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m loss = F.cross_entropy(x, y)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(split, loss.item())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mLinear3D.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    152\u001b[39m x = x.view(B * T, C)\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Apply linear layer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch * seq_len, out_dim)\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Reshape back to 3D: (batch, seq_len, out_dim)\u001b[39;00m\n\u001b[32m    156\u001b[39m x = x.view(B, T, -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\namegens\\namegens\\src\\layers.py:13\u001b[39m, in \u001b[36mLinear.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m   \u001b[38;5;28mself\u001b[39m.out = \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\n\u001b[32m     14\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m.out += \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacity of 7.96 GiB of which 5.87 GiB is free. Of the allocated memory 816.71 MiB is allocated by PyTorch, and 63.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  # Move batch to GPU (dataset stays on CPU)\n",
    "  x, y = x.to(device), y.to(device)\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  \n",
    "  # Pass through all layers (attention + normalization are now in the layers list)\n",
    "  x = emb\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac56d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "franco.\n",
      "zaba.\n",
      "pastasiastauli.\n",
      "pistita.\n",
      "heltar hebur.\n",
      "purndrun.\n",
      "talaah.\n",
      "lela.\n",
      "jargar.\n",
      "bashian.\n",
      "biat baenrial.\n",
      "catiph tord.\n",
      "klimb.\n",
      "sela get rebul.\n",
      "tessy.\n",
      "rose canthol.\n",
      "dalagnar ornembban.\n",
      "tamaloni.\n",
      "loreth habdin.\n",
      "maraukha.\n",
      "muinga.\n",
      "sahisker alagon.\n",
      "dassen.\n",
      "fvarrreth.\n",
      "faarin.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator(device=device).manual_seed(2147483647 + 22)\n",
    "\n",
    "for _ in range(25):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      emb = C[torch.tensor([context], device=device)] # (1,block_size,n_embd)\n",
    "      \n",
    "      # Pass through all layers (attention + normalization are now in the layers list)\n",
    "      x = emb\n",
    "      for layer in layers:\n",
    "        x = layer(x)\n",
    "      logits = x\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a53bcf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mavira an-suderro\n",
      "kuthuztalian harkyl\n",
      "phass graeldardan\n",
      "kaphaen catur\n",
      "talju aty\n",
      "baior sindidir\n",
      "rocka emandge\n",
      "jackiva de nateth\n",
      "pellas rosend\n",
      "aburak al-the\n",
      "malcirus ealjann\n",
      "bekikka taelbor\n",
      "sahnaeus vurdar\n",
      "shumu nik sankes\n",
      "hyun'son chasar\n",
      "jackin sulfrelgin\n",
      "lamwind zebbinghion\n",
      "atyun savara\n",
      "gius rakuna\n",
      "carmelina dhandrakel\n",
      "beiffin thinte\n",
      "avungrako thaurver\n",
      "mrigoy zaslatome\n",
      "khokanshami aekanish\n",
      "kosu ini horn\n"
     ]
    }
   ],
   "source": [
    "# sample from the model forcing more words\n",
    "g = torch.Generator(device=device).manual_seed(2147483647 + 42)\n",
    "\n",
    "for _ in range(25):\n",
    "    has_space = False\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      emb = C[torch.tensor([context], device=device)] # (1,block_size,n_embd)\n",
    "      \n",
    "      # Pass through all layers (attention + normalization are now in the layers list)\n",
    "      x = emb\n",
    "      for layer in layers:\n",
    "        x = layer(x)\n",
    "      logits = x\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      # if we sample the special '.' token, replace with space if no space, otherwise break\n",
    "      if itos[ix] == ' ':\n",
    "        has_space = True\n",
    "      if ix == 0:\n",
    "        if has_space==False:\n",
    "            ix = stoi[' ']\n",
    "            has_space = True\n",
    "        else:\n",
    "            break\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc8fffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gorina the eongarder\n",
      "hazsan the baernesn\n",
      "richelm the carvid\n",
      "ejak the wath\n",
      "remion the kamr\n",
      "batla the eardiel\n",
      "savarra panialvin the wund pel\n",
      "tapette the wind\n",
      "talber the wyldborg\n",
      "iodra the kumauch\n",
      "sivin the godes\n",
      "teegaros the marter\n",
      "eliyah the ghul-yuzzeod\n",
      "bernie the dild\n",
      "jedobari the naxki\n",
      "fabino the hobitart\n",
      "jyljin the fattle\n",
      "azadia the oogril\n",
      "tarra the dumur\n",
      "rathel the marbow\n",
      "anamalekus the mizder\n",
      "vantaris the clada\n",
      "kyegun the bourd\n",
      "ida the khudet\n",
      "paila the dep\n"
     ]
    }
   ],
   "source": [
    "# sample from the model forcing \"the\"\n",
    "g = torch.Generator(device=device).manual_seed(2147483647 + 67)\n",
    "\n",
    "for _ in range(25):\n",
    "    has_the = False\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      emb = C[torch.tensor([context], device=device)] # (1,block_size,n_embd)\n",
    "      \n",
    "      # Pass through all layers (attention + normalization are now in the layers list)\n",
    "      x = emb\n",
    "      for layer in layers:\n",
    "        x = layer(x)\n",
    "      logits = x\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      # if we sample the special '.' token, replace with space if no space, otherwise break\n",
    "      if ix == 0:\n",
    "        if has_the==False:\n",
    "            context = context[5:] + [stoi[' '], stoi['t'], stoi['h'], stoi['e'], stoi[' ']]\n",
    "            has_the = True\n",
    "            out = out + [stoi[' '], stoi['t'], stoi['h'], stoi['e'], stoi[' ']]\n",
    "        else:\n",
    "            break\n",
    "      else:\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05a0a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92be32f7",
   "metadata": {},
   "source": [
    "### from andrejs\n",
    "train 2.0193495750427246\n",
    "val 2.156538963317871\n",
    "### bigger network\n",
    "train 1.9244529008865356\n",
    "val 2.1407828330993652\n",
    "### adjusted sizes + more data\n",
    "train 1.642111897468567\n",
    "val 2.2296860218048096\n",
    "\n",
    "good names tho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0230e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
